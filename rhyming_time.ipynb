{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import models\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def obs_map(tokens, vocab_list):\n",
    "    \"\"\"HMM can only handle integer sequences, so we\n",
    "    map every word to an integer\"\"\"\n",
    "    mapped_tokens = []\n",
    "    for token in tokens:\n",
    "        mapped_tokens.append(vocab_list.index(token))\n",
    "    return mapped_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"data/shakespeare.txt\", \"r\")\n",
    "text = f.read()\n",
    "poems = text.split(\"\\n\\n\")\n",
    "shakesphere_poems = []\n",
    "for i, poem in enumerate(poems):\n",
    "    poem = poem.replace(\",\", \" , \")\n",
    "    poem = poem.replace(\":\", \" : \")\n",
    "    poem = poem.replace(\"?\", \" ? \")\n",
    "    poem = poem.replace(\";\", \" ; \")\n",
    "    poem = poem.replace(\";\", \" ; \")\n",
    "    poem = poem.replace(\"!\", \" ! \")\n",
    "    poem = poem.replace(\"\\n\", \" \\n \")\n",
    "    poem = poem.replace(\".\", \" . \")\n",
    "    poem = poem.replace(\"(\", \"\")\n",
    "    poem = poem.replace(\")\", \"\")\n",
    "    lines = poem.split(\"\\n\")\n",
    "    if i == 0:\n",
    "        lines = lines[1:]\n",
    "    else:\n",
    "        lines = lines[2:]\n",
    "    shakesphere_poems.append([])\n",
    "    for line in lines:\n",
    "        tokens = line.split(\" \")\n",
    "        tokens = [x.lower() for x in tokens if (x != \"\" and not x.isdigit())]\n",
    "        tokens.insert(0, \"<START>\")\n",
    "        tokens.append(\"<STOP>\")\n",
    "        shakesphere_poems[-1].append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"data/spenser.txt\", \"r\")\n",
    "text = f.read()\n",
    "poems = text.split(\"\\n\\n\")\n",
    "spenser_poems = []\n",
    "for i, poem in enumerate(poems):\n",
    "    if i % 2 == 0:\n",
    "        continue\n",
    "    poem = poem.replace(\",\", \" , \")\n",
    "    poem = poem.replace(\":\", \" : \")\n",
    "    poem = poem.replace(\"?\", \" ? \")\n",
    "    poem = poem.replace(\";\", \" ; \")\n",
    "    poem = poem.replace(\";\", \" ; \")\n",
    "    poem = poem.replace(\"!\", \" ! \")\n",
    "    poem = poem.replace(\"\\n\", \" \\n \")\n",
    "    poem = poem.replace(\".\", \" . \")\n",
    "    poem = poem.replace(\"(\", \"\")\n",
    "    poem = poem.replace(\")\", \"\")\n",
    "    lines = poem.split(\"\\n\")\n",
    "    spenser_poems.append([])\n",
    "    for line in lines:\n",
    "        tokens = line.split(\" \")\n",
    "        tokens = [x.lower() for x in tokens if (x != \"\" and not x.isdigit())]\n",
    "        tokens.insert(0, \"<START>\")\n",
    "        tokens.append(\"<STOP>\")\n",
    "        spenser_poems[-1].append(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "all_poems = []\n",
    "all_poems.extend(shakesphere_poems)\n",
    "# all_poems.extend(spenser_poems)\n",
    "\n",
    "all_poems_backwards = (\n",
    "    []\n",
    ")  # All poems but starts each line with last word of line and reads backwards\n",
    "for poem in all_poems:\n",
    "    all_poems_backwards.append([])\n",
    "    for line in poem:\n",
    "        line = line[1:-1]\n",
    "        if len(line[-1]) == 1:\n",
    "            line = line[:-1]\n",
    "        all_poems_backwards[-1].append(line[::-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mega_list = []\n",
    "for poem in all_poems_backwards:\n",
    "    for line in poem:\n",
    "        mega_list.extend(line)\n",
    "vocab_counts = Counter(mega_list)\n",
    "vocab_list = sorted(vocab_counts.items(), key=lambda x: x[1])\n",
    "vocab_list = [x for (x, y) in vocab_list]\n",
    "vocab_list.reverse()\n",
    "\n",
    "tokenized_poems = []\n",
    "for i in range(len(all_poems_backwards)):\n",
    "    for j in range(len(all_poems_backwards[i])):\n",
    "        tokenized_poems.append(obs_map(all_poems_backwards[i][j], vocab_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "patterns = [[0, 2], [1, 3], [4, 6], [5, 7], [8, 10], [9, 11], [12, 13]]\n",
    "\n",
    "rhyme_dict_temp = []\n",
    "\n",
    "for poem in all_poems_backwards:\n",
    "    if len(poem) != 14:\n",
    "        continue\n",
    "    for pattern in patterns:\n",
    "        word_1 = poem[pattern[0]][0]\n",
    "        word_2 = poem[pattern[1]][0]\n",
    "        in_dict = False\n",
    "        for rhymes in rhyme_dict_temp:\n",
    "            if word_1 in rhymes or word_2 in rhymes:\n",
    "                rhymes.add(word_1)\n",
    "                rhymes.add(word_2)\n",
    "                in_dict = True\n",
    "                break\n",
    "        if not in_dict:\n",
    "            rhyme_dict_temp.append(set([word_1, word_2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rhyme_dict = []\n",
    "for i in range(len(rhyme_dict_temp)):\n",
    "    for j in range(i+1, len(rhyme_dict_temp)):\n",
    "        if rhyme_dict_temp[i] & rhyme_dict_temp[j]:\n",
    "            rhyme_dict_temp[i] = rhyme_dict_temp[i].union(rhyme_dict_temp[j])\n",
    "            rhyme_dict_temp[j].clear()\n",
    "\n",
    "for i in range(len(rhyme_dict_temp)):\n",
    "    if rhyme_dict_temp[i]:\n",
    "        rhyme_dict.append(rhyme_dict_temp[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsupervised Learning Begins\n",
      "Iteration 20  - And Input 2154"
     ]
    }
   ],
   "source": [
    "model = models.unsupervised_HMM(tokenized_poems, 16, 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "modified_vocab_list = []\n",
    "for vocab in vocab_list:\n",
    "    if vocab[-1] == \"'\":\n",
    "        vocab = vocab[:-1]\n",
    "    modified_vocab_list.append(vocab)\n",
    "\n",
    "f = open(\"data/Syllable_dictionary.txt\", \"r\")\n",
    "text = f.read()\n",
    "lines = text.split(\"\\n\")\n",
    "word_to_syllables = dict()\n",
    "syllables_to_word = dict()\n",
    "for line in lines:\n",
    "    words = line.split(\" \")\n",
    "    if words[0] not in modified_vocab_list:\n",
    "        continue\n",
    "    word = modified_vocab_list.index(words[0])\n",
    "    count = words[-1]\n",
    "    if \"E\" in count:\n",
    "        count = words[-2]\n",
    "    word_to_syllables[word] = int(count)\n",
    "\n",
    "    if word_to_syllables[word] in syllables_to_word.keys():\n",
    "        syllables_to_word[word_to_syllables[word]].append(word)\n",
    "    else:\n",
    "        syllables_to_word[word_to_syllables[word]] = [word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def reverse_obs_map(tokens, vocab_list):\n",
    "    \"\"\"For unmapping words back to real tokens\"\"\"\n",
    "    unmapped_tokens = []\n",
    "    for token in tokens:\n",
    "        unmapped_tokens.append(vocab_list[token])\n",
    "    return unmapped_tokens\n",
    "\n",
    "\n",
    "def sample_line(hmm, vocab_list, end_word, end_punctuation=\"\", max_words=10):\n",
    "    start_token = obs_map([end_word], vocab_list)[0]\n",
    "    emission, states = hmm.generate_emission(max_words, start_token)\n",
    "    sentence = emission[::-1]\n",
    "    sentence.append(start_token)\n",
    "\n",
    "    syllables = [\n",
    "        word_to_syllables[word] if (word in word_to_syllables.keys()) else 0\n",
    "        for word in sentence\n",
    "    ]\n",
    "    sums = [sum(syllables[i:]) for i in range(len(syllables))]\n",
    "    for i in range(len(sums)):\n",
    "        if sums[i] == sums[i + 1]:\n",
    "            i += 1\n",
    "        if sums[i] == 10:\n",
    "            sentence = sentence[i:]\n",
    "            break\n",
    "        if sums[i] < 10:\n",
    "            sentence = sentence[i:]\n",
    "            sentence.insert(0, random.choice(syllables_to_word[10 - sums[i]]))\n",
    "            break\n",
    "\n",
    "    sentence = reverse_obs_map(sentence, vocab_list)\n",
    "    output = \" \".join(sentence).capitalize()\n",
    "    output = output.replace(\" i \", \" I \")\n",
    "    output = output.replace(\" .\", \".\")\n",
    "    output = output.replace(\" ?\", \"?\")\n",
    "    output = output.replace(\" ,\", \",\")\n",
    "    output = output.replace(\" :\", \":\")\n",
    "    output = output.replace(\" ;\", \";\")\n",
    "    output = output.replace(\" !\", \"!\")\n",
    "    output = output + end_punctuation\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That land that couplement in of measure:\n",
      "Some thoughts for on a being that subscribes\n",
      "And and misprision when days, the leisure,\n",
      "Stars then thou can love for thou brass, one tribes,\n",
      "Force alive unbless believe much hide style:\n",
      "Given unthrift which for seem a think sea:\n",
      "Lo upon is I love think fight compile\n",
      "Most now bring, may gift for in sick my plea:\n",
      "True that my tattered oaths on injuries:\n",
      "Still razed mine for all hath they survey\n",
      "Banks the diest to another enemies:\n",
      "All than of subject this grieved careful sway.\n",
      "Truth to red died be be looked the not ward:\n",
      "Heart by thou particulars the here's guard.\n",
      "\n",
      "What though that a tattered thereby their, sheds,\n",
      "Fall her hope truth out act a face staineth.\n",
      "Hear'st chronicle as their true untrue breeds\n",
      "What's loving with, true filled things disdaineth,\n",
      "Which reasons good thy men thee the befits:\n",
      "And catch self not and tongue any will pace\n",
      "Shall see that that, lov'st marble is commits.\n",
      "Heavy in receive poor that level race.\n",
      "Which beauty holds music happier compile,\n",
      "To she are is kind brings come not relief.\n",
      "Arts special despise minutes yours then style,\n",
      "Your, times good, bastard how do distilled thief:\n",
      "Whence me war and seeming faces suspect,\n",
      "Can both I for as crushed being effect.\n",
      "\n",
      "When with seeting night more night one shape loved:\n",
      "Me other anon but thus my shaken:\n",
      "Break is will knows the you perforce, thine proved,\n",
      "Love should in husband's the buried taken,\n",
      "There though not thee is out true wantonly:\n",
      "Not, when as for another me perceived:\n",
      "Water I that into truest seals dye\n",
      "To four youth his suspect us deceived:\n",
      "Of mistress with they sake the what make thy account,\n",
      "What I often to words sweet earth fever.\n",
      "As I own he lov'st from I, shorn surmount\n",
      "Signs thy angel glass say lasting never,\n",
      "Hideous she love else less possession rents:\n",
      "Babe not of his gave sweet praise ornaments.\n",
      "\n",
      "That thou from every when cheap hath many,\n",
      "Nor with by in greater impanelled,\n",
      "As attending large though every any,\n",
      "The for by a bear me determined\n",
      "Glorious in form with a love-god possessed\n",
      "Would no when the repose chose thou for white:\n",
      "Prison which part in say thou you in least\n",
      "Thou will hast thou and thou even by night\n",
      "Shown make child leads fool to dull, removed show.\n",
      "Fine thee is outlive my assemble tomb\n",
      "Tears and and the pen with that own thy woe:\n",
      "Faith thy the he o'ertake stealth, smell this doom.\n",
      "Check at youth on when doth will over-plus,\n",
      "Affections hallowed that my looks the thus.\n",
      "\n",
      "Do for wherever, seek respect needing:\n",
      "Love hath thy of sorrow, sweet speak denote\n",
      "In since my up envy outworn feeding,\n",
      "Their shall make wish and stars the into dote,\n",
      "Warmed child in slight thy love slandered account:\n",
      "With friend with summer's these eyed hours thus,\n",
      "Could think salutation paid fire surmount,\n",
      "What thine, fair another read over-plus\n",
      "Both trust lost me world methinks than should filed,\n",
      "By thou loved been the the constancy forth:\n",
      "So thou this by pierced to in stand compiled:\n",
      "Unused cost but this yet thy self worth.\n",
      "Dear world ah that her day doth field amends:\n",
      "Abundance that proof be, what no depends.\n",
      "\n",
      "Canker both although that for me word had,\n",
      "Draw full, from, feeble render when it frame,\n",
      "And of is never stay tires as this bad.\n",
      "Removed doth me for by this or thee fame\n",
      "Thy thee eternal since soul renewest:\n",
      "A the are find as love, how releasing.\n",
      "As deserves of measure base which viewest\n",
      "More wilt is lame to my, by possessing,\n",
      "Their if but word in that hath, that indeed:\n",
      "Sweets makes the this to thing time come control,\n",
      "Quick is black, with eye but, and some shown read.\n",
      "Change my nature's more than I the walls soul\n",
      "Shall sum that the happy been best joy beard\n",
      "So the in tattered kinds thy things root herd.\n",
      "\n",
      "Succession keep be that plague doth gulls gaol,\n",
      "Could love's the most she me iniquity,\n",
      "If dull eyes winters of, doth every bail,\n",
      "Advised when see, wolf spite antiquity\n",
      "By all sin against i'll more sight depends:\n",
      "In of blood saw not a things born feeding\n",
      "Import that men, besmeared, book nor amends:\n",
      "Self whereof suffered in fortune needing.\n",
      "Then disgrace more blood, and rank twain fulfil,\n",
      "Consecrate thy day her worth attainted\n",
      "Evil flies more bettered that love of age 'will',\n",
      "Tune truth your weep nine verse in thee painted\n",
      "My for sometime fears him eyes I evil:\n",
      "O'er thee of best beauty their born devil.\n",
      "\n",
      "The is and but then whose the blenches win,\n",
      "I ocean reviewest or with fair hour.\n",
      "The turns to see, my, replete were within\n",
      "Thou body's is nor widow do which sour\n",
      "Of grace through new fast times thou when and foes:\n",
      "Where be prognosticate when while in now,\n",
      "Body I remember hast former knows\n",
      "Love world will perceive my never the brow.\n",
      "Is art say it while didst the heart, thou so,\n",
      "By fears, suffer alive and rich knights told:\n",
      "Speak that thou thou universe wilful-slow\n",
      "More whom do the nor their whether uphold.\n",
      "And should so him take having invited:\n",
      "God that that what sweet must kings delighted.\n",
      "\n",
      "Of which picture do dry may great confounds\n",
      "His vassalage that self for love's him made,\n",
      "It easy her is and being in sounds:\n",
      "Babe who and youth shall chide injury fade.\n",
      "Whilst do believe grieve dissuade excellence,\n",
      "Your name was he, prouder even glance dream\n",
      "Could elder pride loveliness, where expense\n",
      "Lord not thou did not me thou thou extreme:\n",
      "I flowers a me dost looks thou savour\n",
      "For live o 'tis lame and neither then, sounds\n",
      "I turn I my be my you asked favour,\n",
      "Ever thee, so these thou thou in confounds:\n",
      "Be toward and alive a each my viewest,\n",
      "The ill that who forbidden renewest.\n",
      "\n",
      "Lust well on privilage it so veins sang:\n",
      "Thought as without! thing for thee honouring\n",
      "Pure yet have love borne thou leisure and hang,\n",
      "Friend to and will your time yet ruining,\n",
      "It slander she which wood your shade unjust\n",
      "Crown from in were and thou love, at sin word:\n",
      "Towards the mountain twice wherefore eyes when thrust,\n",
      "Want burthen your many, which thoughts afford,\n",
      "Knowing not th' and self what beast golden wing\n",
      "Truth bring unswept untainted who which press,\n",
      "Do what's and of a love eyes niggarding.\n",
      "All me odour hath seen thy wind express:\n",
      "My age this do the wrong and oft longer.\n",
      "Me thus aye, make the false uneared stronger.\n",
      "\n",
      "Make I mourners is the one committed:\n",
      "Back all, thy praise to kind to depart deemed.\n",
      "Making thee, thou be to thou are fitted.\n",
      "Cheap I now hath own disgrace from esteemed:\n",
      "Now hands made nature contracted wary.\n",
      "Changing so likeness sorrow stores taken.\n",
      "Is lov'st I still was he that thou chary:\n",
      "Swift my worth pursuit be tears forsaken\n",
      "Grieved my earth time you destroys fore tired.\n",
      "To large for home verse me must thee on cease.\n",
      "Fell out the muse control false you expired:\n",
      "I judgement when, world form seal takes decease.\n",
      "Sin against I of man of more commence,\n",
      "Ill in than to call eyes among dispense.\n",
      "\n",
      "Worst serving, strength one souls require abhor,\n",
      "And garments' or beauty's think and rehearse\n",
      "Discontent than and posting then that yore\n",
      "Since doth cheek so for measured writes disperse.\n",
      "Will your the made as wherein in blindness\n",
      "As to love a my, if motion provide.\n",
      "That thou the my foist trust so why kindness:\n",
      "Many thus in my store my thou of chide.\n",
      "And rough, I without vainly tied esteemed.\n",
      "Thy the when in by remover belong\n",
      "Breed own falsehood not doth by their breast deemed:\n",
      "Thy shop bestow say, hatred three the wronk.\n",
      "And and beauty that I do churl heart, cheek.\n",
      "Youth thy or thee no and all, say with seek.\n",
      "\n",
      "Height contents of abuses if cruel:\n",
      "Conspire modern a when thou but confound,\n",
      "Move and is thee, marriage I know of fuel\n",
      "Doting praise less with hate which plague crowned:\n",
      "I compare my deserves a thee in land\n",
      "Drinks I love and dead, that eyes knights belongs.\n",
      "Me when but what of sunset this down stand:\n",
      "Enough brave upon make that water wrongs:\n",
      "Print o what and such care thus love's self hide,\n",
      "The who hope I tongues but to that, in dwell.\n",
      "And drops my doing the to do but ride,\n",
      "And mind friend at me shadow, black thee hell.\n",
      "Own best who, thou to that lover's shame youth.\n",
      "My that, may with, not your not survey truth.\n",
      "\n",
      "Strong cold I account it bear answer kings.\n",
      "My they limbs, and is cruel fair amends.\n",
      "Still I as it loss self-willed, spites far things\n",
      "Oft to beauty as thy him cold depends\n",
      "To I this heavy fresh youth bring misplaced\n",
      "It me by water thoughts longing, and gone\n",
      "Words how, wilt for the for best to disgraced,\n",
      "Were much good so thy my loves pain foregone:\n",
      "Dead upon took to thing their special-blest.\n",
      "Mistress' when all my dear-purchased new fall:\n",
      "Is and to men love is who theirs sick west\n",
      "That to consum'st my, cause upon of all\n",
      "Render be another abundance sour:\n",
      "That of self, eye's treasure, this shows since hour.\n",
      "\n",
      "Breast which dull if well longer mistaking,\n",
      "If perjured be worship the to comment\n",
      "Unprovident some carve doth old making.\n",
      "Of power cast brief lawful their me moment:\n",
      "Rich mourn I eye this from of show devised.\n",
      "Denote is thine to nor is west untrimmed\n",
      "Thither hated thou always sympathized\n",
      "Swift thoughts herein princes praise, woeful dimmed:\n",
      "Lascivious I a true reigned ruining,\n",
      "That will self, the followed that state self-killed\n",
      "Loves poor thy burn truth but bind honouring:\n",
      "Sure wailing precious child self his distilled:\n",
      "Thou yellow judgment music to then lack.\n",
      "Rack did! thy extant so with of thee black.\n",
      "\n",
      "Nobler to past esteem impiety.\n",
      "So with not war whilst he eyes are that finds\n",
      "Grieved to in do decay society:\n",
      "But from shifts looks him of heart canst he winds.\n",
      "Never thy the beauty springs lovely grave:\n",
      "Name heart other here and shall by thee keep,\n",
      "Heart's been robbery than which that worse that have,\n",
      "Wife by that time's the, I use and there, steep.\n",
      "Like profit pen in the self friends longer,\n",
      "Thee shall slandered but from by made hast gaol\n",
      "That but hymns or her muse me, doth stronger,\n",
      "Hath of thine but with thus, which whose strive bail.\n",
      "Why guilty kind should pretty skill desire:\n",
      "Foul I when the deep parts eclipse conspire.\n",
      "\n",
      "Love's, each my spites, thou do for world forsake\n",
      "To she, be and, have both of far creature,\n",
      "Enough, hear red, dress to known lies partake:\n",
      "Date wretch love I wilt and love from feature.\n",
      "And the makes sweet, and slave this very light,\n",
      "Poison not deep vassalage liberty:\n",
      "Hell the for I my proving be tears sight.\n",
      "To when o will like permit injury,\n",
      "Compared stays I use all thy thee needing,\n",
      "Feathered have is thou doth self-killed amends,\n",
      "Doth muse, not eyes how infant's prove feeding\n",
      "Where joy away and to confounds depends,\n",
      "Absence errors straight being great true hooks.\n",
      "His then doth I apple that of strive looks.\n",
      "\n",
      "Me if outward departest possessing\n",
      "Writes love self-example? clock ruining,\n",
      "Earth think and none to that out releasing.\n",
      "The unlooked and I my pride honouring:\n",
      "Costs hung of thy which thy I from kindness:\n",
      "On them show terms their paid have all her bar\n",
      "What faith know my this died compare blindness.\n",
      "I shall and of thou is the love, the war.\n",
      "Dost deny when makes to ten over-plus,\n",
      "Come to thing but do conquest was on mud:\n",
      "Nothing of worth this dost for thy fade thus,\n",
      "Have rondure art show my love though thou bud\n",
      "Lambs but no and service can thy blood turned:\n",
      "Thrice have and fall I love's her possessed burned.\n",
      "\n",
      "A the more still and a true, that as feel,\n",
      "Eye have sweet when such your unprovident:\n",
      "Think, canst to just varying so answer steel,\n",
      "Life stay not time he other evident,\n",
      "Bear'st was by I reason is evident:\n",
      "When was I invention enjoyed gazeth,\n",
      "Your thoughts pen that no war unprovident,\n",
      "For that, dear their for in seem amazeth.\n",
      "Of beauty with my worths verse a-doting\n",
      "The hold reason it me sickness thou shown,\n",
      "Is gracious am that if should chest nothing,\n",
      "Which though his flower world not world thing wits own,\n",
      "Near enjoys by when seem purposed behind.\n",
      "Least for on let stronger time than this mind.\n",
      "\n",
      "Ear seconds to, painting the do shines kings,\n",
      "Sometime whereon needs the belied confound,\n",
      "Pretty, thou from thy grave twenty my brings\n",
      "The thee and wondrous confounding crowned:\n",
      "Costs thou sun else sober determinate.\n",
      "My seals sea you tickled messengers grow.\n",
      "At inward although what straight estimate\n",
      "To these hush than my thy, and o seem show.\n",
      "Love borrowed trespass rising all allayed:\n",
      "No yet now seest of adjunct for belongs.\n",
      "He jealous beauty methinks what, with said.\n",
      "Those and truth give of thus eye not sick, wrongs\n",
      "The muse eyes thus strikes name thought away gems:\n",
      "Carved the old heart love have dost dress laid hems.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    sample_poem = [[] for _ in range(14)]\n",
    "\n",
    "    for i, pattern in enumerate(patterns):\n",
    "        j = random.choice(range(len(rhyme_dict)))\n",
    "        end_word1 = random.choice([x for x in rhyme_dict[j]])\n",
    "        end_word2 = random.choice([x for x in rhyme_dict[j] if (x != end_word1)])\n",
    "\n",
    "        end_punc1 = random.choice([\"\", \",\", \":\", \".\"])\n",
    "        end_punc2 = random.choice([\"\", \",\", \":\", \".\"])\n",
    "        if pattern[1] == 13:\n",
    "            end_punc2 = \".\"\n",
    "\n",
    "        sample_poem[pattern[0]] = sample_line(\n",
    "            model, vocab_list, end_word1, end_punc1\n",
    "        )\n",
    "        sample_poem[pattern[1]] = sample_line(\n",
    "            model, vocab_list, end_word2, end_punc2\n",
    "        )\n",
    "\n",
    "    print(\"\\n\".join(sample_poem))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Data Shakespeare\n",
      " Poem 153\n",
      " Finished loading\n",
      "\n",
      " Making Vocabulary\n",
      "Unsupervised Learning Begins\n",
      "Iteration 14  - And Input 125"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 383\u001B[0m\n\u001B[0;32m    380\u001B[0m         model\u001B[38;5;241m.\u001B[39msample_sentence(\u001B[38;5;241m500\u001B[39m)\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m--> 383\u001B[0m     \u001B[43mexperiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    384\u001B[0m     lstm_experiment()\n",
      "Cell \u001B[1;32mIn[1], line 363\u001B[0m, in \u001B[0;36mexperiment\u001B[1;34m()\u001B[0m\n\u001B[0;32m    361\u001B[0m     mapped_token_list\u001B[38;5;241m.\u001B[39mappend(obs_map(tokens, vocab_list))\n\u001B[0;32m    362\u001B[0m     mega_list\u001B[38;5;241m.\u001B[39mextend(obs_map(tokens, vocab_list))\n\u001B[1;32m--> 363\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsupervised_HMM\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmapped_token_list\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    364\u001B[0m text \u001B[38;5;241m=\u001B[39m text_to_wordcloud(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(vocab_list), show\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    365\u001B[0m obs, obs_mape \u001B[38;5;241m=\u001B[39m parse_observations(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(vocab_list))\n",
      "File \u001B[1;32m~\\PycharmProjects\\CS155_PROJECT3\\models.py:577\u001B[0m, in \u001B[0;36munsupervised_HMM\u001B[1;34m(X, n_states, N_iters, rng)\u001B[0m\n\u001B[0;32m    575\u001B[0m \u001B[38;5;66;03m# Train an HMM with unlabeled data.\u001B[39;00m\n\u001B[0;32m    576\u001B[0m HMM \u001B[38;5;241m=\u001B[39m HiddenMarkovModel(A, O)\n\u001B[1;32m--> 577\u001B[0m \u001B[43mHMM\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsupervised_learning\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mN_iters\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    578\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m HMM\n",
      "File \u001B[1;32m~\\PycharmProjects\\CS155_PROJECT3\\models.py:353\u001B[0m, in \u001B[0;36mHiddenMarkovModel.unsupervised_learning\u001B[1;34m(self, X, N_iters)\u001B[0m\n\u001B[0;32m    351\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m curr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mL):\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m nxt \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mL):\n\u001B[1;32m--> 353\u001B[0m         P_curr_nxt[curr][nxt] \u001B[38;5;241m=\u001B[39m alphas[t][curr] \\\n\u001B[0;32m    354\u001B[0m                                 \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mA[curr][nxt] \\\n\u001B[0;32m    355\u001B[0m                                 \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mO[nxt][x[t]] \\\n\u001B[0;32m    356\u001B[0m                                 \u001B[38;5;241m*\u001B[39m betas[t \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m][nxt]\n\u001B[0;32m    358\u001B[0m \u001B[38;5;66;03m# Normalize:\u001B[39;00m\n\u001B[0;32m    359\u001B[0m norm \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#THIS IS WHAT YOU RUN TO GET YOUR POEMS:\n",
    "import re\n",
    "from models import HiddenMarkovModel as HMM\n",
    "import models\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from collections import Counter\n",
    "import random\n",
    "# from embeding_utils import make_embed_model  , convert_text\n",
    "# from gensim.models import word2vec\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def load_and_tokenize_shakespeare():\n",
    "    '''This Loads data from the shakespeare.txt file.\n",
    "    It should return a list where each element is a poem.\n",
    "    That poem should be tokenized (ie it is a list where\n",
    "    each element is a token. Each poem starts with\n",
    "    the <START> token and ends with the <STOP> token.)'''\n",
    "    print(\"Reading Data Shakespeare\")\n",
    "    f = open('data/shakespeare.txt','r')\n",
    "    text = f.read()\n",
    "    text = text.lower()\n",
    "    poems = text.split('\\n\\n')\n",
    "    token_list = []\n",
    "    for i , poem in enumerate(poems):\n",
    "        print(f\"\\r Poem {i}\", end='')\n",
    "        poem = poem.replace(',', ' , ')\n",
    "        poem = poem.replace(':', ' : ')\n",
    "        poem = poem.replace('?', ' ? ')\n",
    "        poem = poem.replace(';', ' ; ')\n",
    "        poem = poem.replace(';', ' ; ')\n",
    "        poem = poem.replace('!', ' ! ')\n",
    "        poem = poem.replace('\\n', ' \\n ')\n",
    "        poem = poem.replace('.',' . ')\n",
    "        poem = poem.replace('(','')\n",
    "        poem = poem.replace(')','')\n",
    "        tokens = poem.split(' ')\n",
    "        tokens.insert(0,'<START>')\n",
    "        tokens.append('<STOP>')\n",
    "        tokens = [x for x in tokens if (x != '' and not x.isdigit())]\n",
    "        token_list.append(tokens)\n",
    "\n",
    "    print(\"\\n Finished loading\")\n",
    "    print(\"\\n Making Vocabulary\")\n",
    "    mega_list = []\n",
    "    for tokens in token_list:\n",
    "        mega_list.extend(tokens)\n",
    "    vocab_counts = Counter(mega_list)\n",
    "    vocab_list = sorted(vocab_counts.items(), key=lambda x: x[1])\n",
    "    vocab_list = [x for (x,y) in vocab_list]\n",
    "    vocab_list.reverse()\n",
    "    #Returns a list of tokens\n",
    "    # and also a vocabulary sorted by the frequency of the tokens\n",
    "    return token_list , vocab_list\n",
    "\n",
    "def load_and_tokenize_spencer():\n",
    "    '''This Loads data from the shakespeare.txt file.\n",
    "    It should return a list where each element is a poem.\n",
    "    That poem should be tokenized (ie it is a list where\n",
    "    each element is a token. Each poem starts with\n",
    "    the <START> token and ends with the <STOP> token.)'''\n",
    "    print(\"Reading Data Spencer\")\n",
    "    f = open('data/spenser.txt','r')\n",
    "    text = f.read()\n",
    "    text = text.lower()\n",
    "    poems = text.split('\\n\\n')\n",
    "    token_list = []\n",
    "    for i , poem in enumerate(poems):\n",
    "        print(f\"\\r Poem {i}\", end='')\n",
    "        poem = poem.replace(',', ' , ')\n",
    "        poem = poem.replace(':', ' : ')\n",
    "        poem = poem.replace('?', ' ? ')\n",
    "        poem = poem.replace(';', ' ; ')\n",
    "        poem = poem.replace(';', ' ; ')\n",
    "        poem = poem.replace('!', ' ! ')\n",
    "        poem = poem.replace('\\n', ' \\n ')\n",
    "        poem = poem.replace('.',' . ')\n",
    "        poem = poem.replace('(','')\n",
    "        poem = poem.replace(')','')\n",
    "        tokens = poem.split(' ')\n",
    "        tokens.insert(0,'<START>')\n",
    "        tokens.append('<STOP>')\n",
    "        tokens = [x for x in tokens if (x != '' and x != '\\t')]\n",
    "        token_list.append(tokens)\n",
    "\n",
    "    print(\"\\n Finished loading\")\n",
    "    print(\"\\n Making Vocabulary\")\n",
    "    mega_list = []\n",
    "    for tokens in token_list:\n",
    "        mega_list.extend(tokens)\n",
    "    vocab_counts = Counter(mega_list)\n",
    "    vocab_list = sorted(vocab_counts.items(), key=lambda x: x[1])\n",
    "    vocab_list = [x for (x,y) in vocab_list]\n",
    "    vocab_list.reverse()\n",
    "    #Returns a list of tokens\n",
    "    # and also a vocabulary sorted by the frequency of the tokens\n",
    "    return token_list , vocab_list\n",
    "\n",
    "\n",
    "def load_and_tokenize_collated():\n",
    "    '''This Loads data from the shakespeare.txt file.\n",
    "    It should return a list where each element is a poem.\n",
    "    That poem should be tokenized (ie it is a list where\n",
    "    each element is a token. Each poem starts with\n",
    "    the <START> token and ends with the <STOP> token.)'''\n",
    "    print(\"Reading Data Spencer\")\n",
    "    f = open('data/collated_sonnets.txt','r')\n",
    "    text = f.read()\n",
    "    text = text.lower()\n",
    "    poems = text.split('\\n\\n')\n",
    "    token_list = []\n",
    "    for i , poem in enumerate(poems):\n",
    "        print(f\"\\r Poem {i}\", end='')\n",
    "        poem = poem.replace(',', ' , ')\n",
    "        poem = poem.replace(':', ' : ')\n",
    "        poem = poem.replace('?', ' ? ')\n",
    "        poem = poem.replace(';', ' ; ')\n",
    "        poem = poem.replace(';', ' ; ')\n",
    "        poem = poem.replace('!', ' ! ')\n",
    "        poem = poem.replace('\\n', ' \\n ')\n",
    "        poem = poem.replace('--', ' , ')\n",
    "        poem = poem.replace('.',' . ')\n",
    "        poem = poem.replace('(','')\n",
    "        poem = poem.replace(')','')\n",
    "        tokens = poem.split(' ')\n",
    "        tokens.insert(0,'<START>')\n",
    "        tokens.append('<STOP>')\n",
    "        tokens = [x for x in tokens if (x != '' and x != '\\t')]\n",
    "        token_list.append(tokens)\n",
    "\n",
    "    print(\"\\n Finished loading\")\n",
    "    print(\"\\n Making Vocabulary\")\n",
    "    mega_list = []\n",
    "    for tokens in token_list:\n",
    "        mega_list.extend(tokens)\n",
    "    vocab_counts = Counter(mega_list)\n",
    "    vocab_list = sorted(vocab_counts.items(), key=lambda x: x[1])\n",
    "    vocab_list = [x for (x,y) in vocab_list]\n",
    "    vocab_list.reverse()\n",
    "    #Returns a list of tokens\n",
    "    # and also a vocabulary sorted by the frequency of the tokens\n",
    "    return token_list , vocab_list\n",
    "\n",
    "\n",
    "\n",
    "def obs_map(tokens, vocab_list):\n",
    "    '''HMM can only handle integer sequences, so we\n",
    "    map every word to an integer'''\n",
    "    mapped_tokens = []\n",
    "    for token in tokens:\n",
    "        mapped_tokens.append(vocab_list.index(token))\n",
    "    return mapped_tokens\n",
    "\n",
    "def reverse_obs_map(tokens,vocab_list):\n",
    "    '''For unmapping words back to real tokens'''\n",
    "    unmapped_tokens = []\n",
    "    for token in tokens:\n",
    "        unmapped_tokens.append(vocab_list[token])\n",
    "    return unmapped_tokens\n",
    "\n",
    "class ObsMapEmbed:\n",
    "    #This class is for use in the LSTM.\n",
    "    def __init__(self,vocab):\n",
    "        self.vocab = vocab\n",
    "\n",
    "    def embed(self,tokens):\n",
    "        #Takes a list of words and embeds them.\n",
    "        return th.nn.functional.one_hot(th.tensor(obs_map(tokens,self.vocab)),num_classes = len(self.vocab))\n",
    "\n",
    "    def unembed(self,tokens):\n",
    "        # recieves a list of one hot embedded tokens and then turns them into words.\n",
    "\n",
    "        return reverse_obs_map(tokens,self.vocab)\n",
    "\n",
    "def sample_sentence(hmm, vocab_list, max_words=1000):\n",
    "    # Get reverse map.\n",
    "\n",
    "    # Sample and convert sentence.\n",
    "    end_token = obs_map(['<STOP>'],vocab_list)[0]\n",
    "    start_token = obs_map(['<START>'],vocab_list)[0]\n",
    "    emission, states = hmm.generate_emission(max_words,start_token,end_token=end_token)\n",
    "    sentence = emission\n",
    "    sentence = reverse_obs_map(sentence,vocab_list)\n",
    "    output = ' '.join(sentence).capitalize()\n",
    "    output = output.replace(' <start>','')\n",
    "    output = output.replace(' .','.')\n",
    "    output = output.replace(' ?','?')\n",
    "    output = output.replace(' ,',',')\n",
    "    output = output.replace(' :',':')\n",
    "    output = output.replace(' ;',';')\n",
    "    output = output.replace(' !','!')\n",
    "    output = output.replace(' \\n ','\\n')\n",
    "    print(output)\n",
    "    #TODO figure out how to output the sates as well,\n",
    "    #So that they also end at <STOP>\n",
    "    return output\n",
    "\n",
    "\n",
    "def load_and_tokenize_spenser():\n",
    "    '''This Loads data from the spenser.txt file.\n",
    "    It should return a list where each element is a poem.\n",
    "    That poem should be tokenized (ie it is a list where\n",
    "    each element is a token. Each poem starts with\n",
    "    the <START> token and ends with the <STOP> token.'''\n",
    "    pass\n",
    "    #TODO PROBABLY BASED ON SHAKESPEARE VERSION\n",
    "\n",
    "def train_HMM(tokens, model):\n",
    "    '''train an HMM on a set of tokens\n",
    "    Where the tokens are of the form outputed by load_and_tokenize'''\n",
    "    #TODO: RN the HMM can only handle numbers\n",
    "    #TODO JUST USE THEIR CODE.\n",
    "    pass\n",
    "\n",
    "\n",
    "def LSTM_loss(y,y_hat):\n",
    "    return th.mean(-th.log(th.cosine_similarity(y,y_hat)))\n",
    "\n",
    "def train_LSTM(model,X,batch_size,num_epochs,lr):\n",
    "    '''\n",
    "\n",
    "    :param model: an LSTM model\n",
    "    :param X: a list of sequences\n",
    "    :param batch_size:\n",
    "    :param num_epochs:\n",
    "    :return:\n",
    "    '''\n",
    "    Y = [model.embedding_model.embed(x[1:]) for x in X]\n",
    "    X = [model.embedding_model.embed(x[:-1]) for x in X]\n",
    "    train_dataset = data_utils.TensorDataset(th.nn.utils.rnn.pad_sequence(X).permute([1,0,2]).float(), th.nn.utils.rnn.pad_sequence(Y).permute([1,0,2]).float())\n",
    "    data = data_utils.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr)\n",
    "    loss_fun = nn.CrossEntropyLoss(reduction='mean')\n",
    "    for epoch in range(num_epochs):\n",
    "        avg_loss = 0\n",
    "        counter = 0\n",
    "        for x, y in data:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = loss_fun(th.flatten(y_hat,0,1), th.flatten(y,0,1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            avg_loss += loss\n",
    "            counter += 1\n",
    "        print(f\"epoch - {epoch} avg_loss: {avg_loss / counter}\")\n",
    "        model.sample_sentence(max_tokens=15)\n",
    "    print(\"Finished\")\n",
    "    return model\n",
    "\n",
    "def mask():\n",
    "    # Parameters.\n",
    "    r = 128\n",
    "    d = 2 * r + 1\n",
    "\n",
    "    # Get points in a circle.\n",
    "    y, x = np.ogrid[-r:d-r, -r:d-r]\n",
    "    circle = (x**2 + y**2 <= r**2)\n",
    "\n",
    "    # Create mask.\n",
    "    mask = 255 * np.ones((d, d), dtype=np.uint8)\n",
    "    mask[circle] = 0\n",
    "\n",
    "    return mask\n",
    "\n",
    "def text_to_wordcloud(text, max_words=50, title='', show=True):\n",
    "    plt.close('all')\n",
    "\n",
    "    # Generate a wordcloud image.\n",
    "    wordcloud = WordCloud(random_state=0,\n",
    "                          max_words=max_words,\n",
    "                          background_color='white',\n",
    "                          mask=mask()).generate(text)\n",
    "\n",
    "    # Show the image.\n",
    "    if show:\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(title, fontsize=24)\n",
    "        plt.show()\n",
    "        # save the image\n",
    "        wordcloud.to_file(f\"wordcloud_{title}.png\")\n",
    "\n",
    "    return wordcloud\n",
    "def parse_observations(text):\n",
    "    # Convert text to dataset.\n",
    "    lines = [line.split() for line in text.split('\\n') if line.split()]\n",
    "\n",
    "    obs_counter = 0\n",
    "    obs = []\n",
    "    obs_map = {}\n",
    "\n",
    "    for line in lines:\n",
    "        obs_elem = []\n",
    "\n",
    "        for word in line:\n",
    "            word = re.sub(r'[^\\w]', '', word).lower()\n",
    "            if word not in obs_map:\n",
    "                # Add unique words to the observations map.\n",
    "                obs_map[word] = obs_counter\n",
    "                obs_counter += 1\n",
    "\n",
    "            # Add the encoded word.\n",
    "            obs_elem.append(obs_map[word])\n",
    "\n",
    "        # Add the encoded sequence.\n",
    "        obs.append(obs_elem)\n",
    "\n",
    "    return obs, obs_map\n",
    "\n",
    "def obs_map_reverser(obs_map):\n",
    "    obs_map_r = {}\n",
    "\n",
    "    for key in obs_map:\n",
    "        obs_map_r[obs_map[key]] = key\n",
    "\n",
    "    return obs_map_r\n",
    "\n",
    "def states_to_wordclouds(hmm, obs_map, max_words=50, show=True):\n",
    "    # Initialize.\n",
    "    M = 100000\n",
    "    n_states = len(hmm.A)\n",
    "    obs_map_r = obs_map_reverser(obs_map)\n",
    "    wordclouds = []\n",
    "\n",
    "    # Generate a large emission.\n",
    "    emission, states = hmm.generate_emission(M)\n",
    "\n",
    "    # For each state, get a list of observations that have been emitted\n",
    "    # from that state.\n",
    "    obs_count = []\n",
    "    for i in range(n_states):\n",
    "        obs_lst = np.array(emission)[np.where(np.array(states) == i )[0]]\n",
    "        # remove any numbers above 2000\n",
    "        obs_lst = obs_lst[obs_lst < 2000]\n",
    "        obs_count.append(obs_lst)\n",
    "\n",
    "    # For each state, convert it into a wordcloud.\n",
    "    for i in range(n_states):\n",
    "        obs_lst = obs_count[i]\n",
    "        sentence = [obs_map_r[j] for j in obs_lst]\n",
    "        sentence_str = ' '.join(sentence)\n",
    "\n",
    "        wordclouds.append(text_to_wordcloud(sentence_str, max_words=max_words, title='State %d' % i, show=show))\n",
    "\n",
    "    return wordclouds\n",
    "\n",
    "\n",
    "def experiment():\n",
    "    '''Makes the Model, Trains the Model, Outputs some poem\n",
    "    examples, then outputs some visualizations.'''\n",
    "    #Load the tokens from Shakespeare\n",
    "    token_list , vocab_list = load_and_tokenize_shakespeare()\n",
    "    #Then map them s.t. each word is an integer\n",
    "    mapped_token_list = []\n",
    "    mega_list = []\n",
    "    for tokens in token_list:\n",
    "        mapped_token_list.append(obs_map(tokens, vocab_list))\n",
    "        mega_list.extend(obs_map(tokens, vocab_list))\n",
    "    model = models.unsupervised_HMM(mapped_token_list,5,20)\n",
    "    text = text_to_wordcloud(\" \".join(vocab_list), show=False)\n",
    "    obs, obs_mape = parse_observations(\" \".join(vocab_list))\n",
    "    states_to_wordclouds(model, obs_mape)\n",
    "    for i in range(40):\n",
    "        print(f\"Sentence {i}\\n\\n\\n\")\n",
    "        sample_sentence(model,vocab_list,300)\n",
    "    print(\"END OF PROGRAM\")\n",
    "\n",
    "def lstm_experiment():\n",
    "    token_list, vocab_list = load_and_tokenize_collated()\n",
    "    embed = ObsMapEmbed(vocab_list)\n",
    "    model = models.LSTM_Poet(400,embed,len(vocab_list))\n",
    "    model = train_LSTM(model, token_list, 16, 30,.01)\n",
    "    print(\"\\n\\n\\n\\n final sample poems:\")\n",
    "    for i in range(40):\n",
    "        print(f\"\\n\\nPoem {i}\\n\" )\n",
    "        model.sample_sentence(500)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    experiment()\n",
    "    lstm_experiment()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}